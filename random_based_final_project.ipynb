{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "B8RuL1xcPrHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 압축 해제\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/2025_1 딥러닝/new_COCO1.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "zip_ref.extractall('/dataset')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Xnem23oFPq-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# psnr, mse 계산 함수\n",
        "# psnr을 계산하기 위해 파이토치 텐서를 넘파이로 변환하는 과정 필요\n",
        "def compute_psnr(img1,img2):\n",
        "    # pytorch 내장 gpu연산을 통해 연산 속도. gpu상에서 텐서 연산을 바로 진행\n",
        "    # gpu->cpu 복사후 numpy로 처리하는 것보다 훨씬 속도가 빠름\n",
        "    mse = torch.mean((img1 - img2)**2) #mse 계산식\n",
        "    psnr = 20 * torch.log10(255.0 / torch.sqrt(mse)) #psnr 계산식 using numpy log10 and sqrt\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "4I8ynNtfQAau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oEOImpnn7V6"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class RandomPatchDataset(Dataset):\n",
        "    \"\"\"\n",
        "    - 원본 512×512 이미지에서 “무작위 Patch”를 미리 샘플링해 두고,\n",
        "      학습 중에는 Patch 좌표만 꺼내서 Upsample·평균화·Concatenate 연산만 수행하도록 최적화.\n",
        "\n",
        "    - K×K 크기의 256×256 패치 M개 → 512×512로 upsample → 평균화  → up256_agg\n",
        "    - K×K 크기의 512×512 패치 M개 → 512×512로 upsample → 평균화  → up512_agg\n",
        "    - plus, 128×128 → 512×512 global upsample → up128\n",
        "\n",
        "    inp = [ up128, up256_agg, up512_agg ]  => (채널 개수 = 3 + 3 + 3 = 9) × 512 × 512\n",
        "\n",
        "    - 메모리 소모: “(x_256, y_256) 좌표 M개” + “(x_512, y_512) 좌표 M개”만 미리 캐시 → 매우 작음.\n",
        "    - 불필요한 feature_cache(idx→(inp,hr))를 제거하여 RAM 절약.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, img_dir: str, K: int, cache_images: bool = True):\n",
        "        \"\"\"\n",
        "        img_dir      : 원본 512×512 이미지 폴더 경로\n",
        "        K            : patch 한 변의 길이 (픽셀)\n",
        "        cache_images : True면 PIL.Image를 메모리에 캐시 (권장 False → 메모리 절약)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert 16384 % (K * K) == 0, \"16384 must be divisible by K*K\"\n",
        "        self.K = K\n",
        "        self.M = 16384 // (K * K)\n",
        "\n",
        "        # 1) 이미지 파일 경로 리스트\n",
        "        self.paths = sorted(glob.glob(os.path.join(img_dir, '*.png')))\n",
        "        # 2) PIL.Image 캐시 여부 (cache_images=False 권장)\n",
        "        self.cache_images = cache_images\n",
        "        self.pil_cache = {} if cache_images else None\n",
        "\n",
        "        # 3) 미리 샘플링한 “256 해상도 무작위 Patch 좌표” / “512 해상도 무작위 Patch 좌표”\n",
        "        #    각각의 key: 이미지 경로, value: [(x1,y1), (x2,y2), ..., (xM,yM)]\n",
        "        self.patch256_coords = {}  # for 256×256 패치\n",
        "        self.patch512_coords = {}  # for 512×512 패치\n",
        "\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "        # 4) 초기화 시점에만 한 번, 모든 이미지 당 M개의 랜덤 좌표 샘플링\n",
        "        self._sample_patch_coords_all_images()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "\n",
        "        # ── 1) PIL 이미지 로드 & 캐시 처리\n",
        "        if self.pil_cache is not None and path in self.pil_cache:\n",
        "            pil_img = self.pil_cache[path]\n",
        "        else:\n",
        "            pil_img = Image.open(path).convert('RGB')\n",
        "            if self.pil_cache is not None:\n",
        "                self.pil_cache[path] = pil_img\n",
        "\n",
        "        # ── 2) HR 타깃 (512×512) → Tensor\n",
        "        hr = self.to_tensor(pil_img)\n",
        "\n",
        "        # ── 3) Global Up-sample: 128×128 → 512×512\n",
        "        lr128 = pil_img.resize((128, 128), Image.BICUBIC)\n",
        "        up128 = F.interpolate(\n",
        "            self.to_tensor(lr128).unsqueeze(0),\n",
        "            size=(512, 512),\n",
        "            mode='bicubic'\n",
        "        ).squeeze(0)  # 결과 shape: [3, 512, 512]\n",
        "\n",
        "        # ── 4) 미리 샘플링된 좌표 (256×256 해상도) 꺼내오기\n",
        "        coords256 = self.patch256_coords[path]  # [(x1,y1), ..., (xM,yM)]\n",
        "        coords512 = self.patch512_coords[path]  # [(u1,v1), ..., (uM,vM)]\n",
        "\n",
        "        # ── 5) Accumulator: upsample → 모아서 평균 (256 패치)\n",
        "        lr256_full = pil_img.resize((256, 256), Image.BICUBIC)\n",
        "        acc256 = []\n",
        "        for (x256, y256) in coords256:\n",
        "            p256 = lr256_full.crop((x256, y256, x256 + self.K, y256 + self.K))\n",
        "            t256 = self.to_tensor(p256).unsqueeze(0)  # [1,3,K,K]\n",
        "            up256 = F.interpolate(t256, size=(512, 512), mode='bicubic')  # [1,3,512,512]\n",
        "            acc256.append(up256)\n",
        "        # torch.cat → [M, 3, 512, 512], 평균 → [3,512,512]\n",
        "        up256_agg = torch.mean(torch.cat(acc256, dim=0), dim=0)\n",
        "\n",
        "        # ── 6) Accumulator: upsample → 모아서 평균 (512 패치)\n",
        "        acc512 = []\n",
        "        for (x512, y512) in coords512:\n",
        "            p512 = pil_img.crop((x512, y512, x512 + self.K, y512 + self.K))\n",
        "            t512 = self.to_tensor(p512).unsqueeze(0)  # [1,3,K,K]\n",
        "            up512 = F.interpolate(t512, size=(512, 512), mode='bicubic')  # [1,3,512,512]\n",
        "            acc512.append(up512)\n",
        "        up512_agg = torch.mean(torch.cat(acc512, dim=0), dim=0)\n",
        "\n",
        "        # ── 7) 세 가지 채널( up128, up256_agg, up512_agg )을 concat → 최종 입력\n",
        "        inp = torch.cat([up128, up256_agg, up512_agg], dim=0)  # shape: [9,512,512]\n",
        "\n",
        "        return inp, hr\n",
        "\n",
        "    def clear_cache(self):\n",
        "        \"\"\"\n",
        "        (Optional) Epoch 단위로 PIL 캐시만 지우고 싶으면 호출.\n",
        "        patch256_coords / patch512_coords는 유지합니다.\n",
        "        \"\"\"\n",
        "        if self.pil_cache is not None:\n",
        "            self.pil_cache.clear()\n",
        "\n",
        "    def resample_patch_coords(self):\n",
        "        \"\"\"\n",
        "        매 Epoch마다 ‘완전히 새로운 Random patch’를 다시\n",
        "        샘플링하고 싶을 때 호출하는 함수.\n",
        "        \"\"\"\n",
        "        self._sample_patch_coords_all_images()\n",
        "\n",
        "    def _sample_patch_coords_all_images(self):\n",
        "        \"\"\"\n",
        "        1) 모든 이미지에 대해\n",
        "           - 256×256 해상도에서 K×K 랜덤 Patch 좌표 M개\n",
        "           - 512×512 해상도에서 K×K 랜덤 Patch 좌표 M개\n",
        "          를 미리 뽑아서 self.patch256_coords, self.patch512_coords에 저장.\n",
        "        2) 이 과정은 __init__에서 한 번 호출되며, 이후\n",
        "           resample_patch_coords()를 통해 재호출 가능.\n",
        "        \"\"\"\n",
        "        # 필요한 변수\n",
        "        H256, W256 = 256, 256\n",
        "        H512, W512 = 512, 512\n",
        "\n",
        "        for path in self.paths:\n",
        "            # 1) 256×256 해상도 Patch 좌표 M개 무작위 샘플링\n",
        "            coords256 = []\n",
        "            for _ in range(self.M):\n",
        "                x256 = np.random.randint(0, W256 - self.K + 1)\n",
        "                y256 = np.random.randint(0, H256 - self.K + 1)\n",
        "                coords256.append((x256, y256))\n",
        "            self.patch256_coords[path] = coords256\n",
        "\n",
        "            # 2) 512×512 해상도 Patch 좌표 M개 무작위 샘플링\n",
        "            coords512 = []\n",
        "            for _ in range(self.M):\n",
        "                x512 = np.random.randint(0, W512 - self.K + 1)\n",
        "                y512 = np.random.randint(0, H512 - self.K + 1)\n",
        "                coords512.append((x512, y512))\n",
        "            self.patch512_coords[path] = coords512\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device : \", device)\n"
      ],
      "metadata": {
        "id": "IySaEEV9Kgrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 복원 네트워크\n",
        "class MyVersionSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=3):\n",
        "        super(MyVersionSRCNN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # 1) Depthwise Conv 5×5 방법-파라미터, 연산량을 모두 감소\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels),\n",
        "            # 2) Pointwise Conv 1×1 → 64채널\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 32, kernel_size=1),         # dimensionality reduction\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)  # reconstruction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x[:, :3] 은 global up128 의 첫 3채널\n",
        "        res = self.layers(x) # 잔차 학습(Residual Learning)---학습속도 계선\n",
        "        return  (res + x[:, :3, :, :]).clamp(0,1)# output range [0,1]\n",
        "\n",
        "# 선택가능 패치 개수 : M = 16384 // (K*K) = 64, so in_ch = 3 + 6*64 = 387\n",
        "model1 = MyVersionSRCNN(in_channels=9).to(device)"
      ],
      "metadata": {
        "id": "UXuX010FPvy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Basic SRCNN (adapted for 9-channel input)\n",
        "class BasicSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(BasicSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, padding=4),  # feature extraction\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),                       # non-linear mapping\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)   # reconstruction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).clamp(0, 1)\n",
        "\n",
        "model2 = BasicSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "hOsetXBePvwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Residual SRCNN\n",
        "class ResidualSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(ResidualSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, padding=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.net(x)\n",
        "        # add global up128 (first 3 channels) as residual connection\n",
        "        return (res + x[:, :3, :, :]).clamp(0, 1)\n",
        "\n",
        "model3 = ResidualSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "HVO5JsSqPq4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Depthwise-Separable SRCNN\n",
        "class DepthwiseSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(DepthwiseSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # depthwise 9x9\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=9, padding=4, groups=in_channels),\n",
        "            # pointwise 1x1\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).clamp(0, 1)\n",
        "\n",
        "model4 = DepthwiseSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "Rd_v9pw7QR4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model1, (9, 512, 512)) # MyVersionSRCNN\n",
        "summary(model2, (9, 512, 512)) # BasicSRCNN\n",
        "summary(model3, (9, 512, 512)) # ResidualSRCNN\n",
        "summary(model4, (9, 512, 512)) # DepthwiseSRCNN"
      ],
      "metadata": {
        "id": "0UHRLPgSQR1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CPU 코어 수:\", os.cpu_count())"
      ],
      "metadata": {
        "id": "tZikAQTRQRzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dataset\n",
        "train_dataset = RandomPatchDataset(img_dir='/dataset/new_COCO1/Train',K=16)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=1, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "test_dataset = RandomPatchDataset(img_dir='/dataset/new_COCO1/Test', K=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=1, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "Z4RfpgIkQRwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset shape 확인\n",
        "print(f\"Train dataset : {len(train_dataset)}\")\n",
        "print(f\"Test dataset : {len(test_dataset)}\")\n",
        "\n",
        "sample_input, sample_output = train_dataset[0]\n",
        "print(f\"Train dataset input shape(3개의 scale의 rgb이미지): {sample_input.shape}\")\n",
        "print(f\"Train dataset output shape(복원된 이미지): {sample_output.shape}\")\n",
        "\n",
        "sample_input, sample_output = test_dataset[0]\n",
        "print(f\"Test dataset input shape: {sample_input.shape}\")\n",
        "print(f\"Test dataset output shape: {sample_output.shape}\")"
      ],
      "metadata": {
        "id": "naXVlnwpQW2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "learning_rate = 1e-3 # 학습률\n",
        "criterion = nn.MSELoss() # loss fuction\n",
        "num_epochs = 10 # number of epochs\n",
        "\n",
        "# 1번모델========================================================\n",
        "# optimizer\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler1 = optim.lr_scheduler.StepLR(optimizer1, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 2번모델==========================================================\n",
        "# optimizer\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler2 = optim.lr_scheduler.StepLR(optimizer2, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 3번모델==========================================================\n",
        "# optimizer\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler3 = optim.lr_scheduler.StepLR(optimizer3, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 4번모델==========================================================\n",
        "# optimizer\n",
        "optimizer4 = optim.Adam(model4.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler4 = optim.lr_scheduler.StepLR(optimizer4, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n"
      ],
      "metadata": {
        "id": "T0qMp5ZoQWz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, scheduler, num_epochs, time_limit_hours=10):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    train_psnr = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_dataset.clear_cache() # epoch마다 캐시 초기화\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_psnr = 0\n",
        "        num_batches = len(train_loader)\n",
        "        scaler = GradScaler()\n",
        "        for input_tensor, target in train_loader:\n",
        "            input_tensor = input_tensor.to(device)  # [B, 9, 512, 512]\n",
        "            target = target.to(device)              # [B, 3, 512, 512]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                output = model(input_tensor)\n",
        "                loss = criterion(output, target)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # PSNR 계산\n",
        "            psnr = compute_psnr(output, target)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_psnr += psnr.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_loss = epoch_loss / num_batches\n",
        "        avg_psnr = epoch_psnr / num_batches\n",
        "        train_loss.append(avg_loss)\n",
        "        train_psnr.append(avg_psnr)\n",
        "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}, Avg PSNR: {avg_psnr:.2f} dB\")\n",
        "\n",
        "        # 시간 제한 확인\n",
        "        elapsed_time = time.time() - start_time\n",
        "        if elapsed_time > time_limit_hours * 3600:\n",
        "            print(\"Training stopped: 10-hour limit reached.\")\n",
        "            break\n",
        "\n",
        "    return model, train_loss, train_psnr\n"
      ],
      "metadata": {
        "id": "h4R0d1a3QWyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('1번 모델 훈련 : MyVersionSRCNN')\n",
        "train_model1, train_loss1, train_psnr1 = train(model1, device, train_dataloader, optimizer1, criterion, scheduler1, num_epochs)\n"
      ],
      "metadata": {
        "id": "qZZ6NtwDQWwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "def display_random_patch(dataset, index, K):\n",
        "    \"\"\"\n",
        "    랜덤으로 추출한 KxK 패치와 원본 이미지를 출력합니다.\n",
        "    패치로 선택되지 않은 영역은 검정색으로 처리합니다.\n",
        "\n",
        "    Args:\n",
        "        dataset (RandomPatchDataset): RandomPatchDataset 객체.\n",
        "        index (int): 데이터셋에서 이미지를 선택할 인덱스.\n",
        "        K (int): 패치의 한 변의 길이 (픽셀).\n",
        "    \"\"\"\n",
        "    path = dataset.paths[index]\n",
        "    pil_img = Image.open(path).convert('RGB')\n",
        "    img_np = np.array(pil_img)\n",
        "\n",
        "    # 미리 샘플링된 좌표 (256×256 해상도) 꺼내오기\n",
        "    coords256 = dataset.patch256_coords[path]\n",
        "\n",
        "    # 미리 샘플링된 좌표 (512×512 해상도) 꺼내오기\n",
        "    coords512 = dataset.patch512_coords[path]\n",
        "\n",
        "    # 256 이미지에 대한 마스크 생성 및 패치 영역 표시\n",
        "    img_256_masked = np.zeros_like(img_np)\n",
        "    lr256_full = pil_img.resize((256, 256), Image.BICUBIC)\n",
        "    lr256_np = np.array(lr256_full)\n",
        "\n",
        "    for (x256, y256) in coords256:\n",
        "        # 256 해상도에서 패치 영역\n",
        "        patch256 = lr256_np[y256 : y256 + K, x256 : x256 + K, :]\n",
        "        # 512 해상도로 확대하여 원래 이미지 위치에 표시 (간단한 방법)\n",
        "        # 실제 interpolate와는 다를 수 있지만, 시각화 목적\n",
        "        x512 = x256 * 2\n",
        "        y512 = y256 * 2\n",
        "        # 확대된 패치 영역 (간단한 반복 사용)\n",
        "        for r in range(K):\n",
        "            for c in range(K):\n",
        "                # 2x2 블록으로 확대하여 512 이미지에 표시\n",
        "                img_256_masked[y512 + r*2 : y512 + r*2 + 2, x512 + c*2 : x512 + c*2 + 2, :] = patch256[r, c, :]\n",
        "\n",
        "    # 512 이미지에 대한 마스크 생성 및 패치 영역 표시\n",
        "    img_512_masked = np.zeros_like(img_np)\n",
        "    for (x512, y512) in coords512:\n",
        "        # 512 해상도에서 패치 영역\n",
        "        patch512 = img_np[y512 : y512 + K, x512 : x512 + K, :]\n",
        "        # 512 이미지에 표시\n",
        "        img_512_masked[y512 : y512 + K, x512 : x512 + K, :] = patch512\n",
        "\n",
        "\n",
        "    # 이미지 출력\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img_np)\n",
        "    plt.title('Original Image (512x512)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(img_256_masked)\n",
        "    plt.title(f'Patches from 256 (K={K}, M={dataset.M})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(img_512_masked)\n",
        "    plt.title(f'Patches from 512 (K={K}, M={dataset.M})')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# train_dataset에서 첫 번째 이미지에 대해 K=16으로 패치 시각화\n",
        "display_random_patch(train_dataset, 0, 16)"
      ],
      "metadata": {
        "id": "kGMDtdqpzQ3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# 테스트 함수 (GPU 사용)\n",
        "def test_model(model, device, test_loader):\n",
        "    model.eval()  # evaluation mode\n",
        "    test_psnr = 0\n",
        "    num_batches = len(test_loader)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for input_tensor, target in test_loader:\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_tensor)\n",
        "\n",
        "            # PSNR 계산\n",
        "            psnr = compute_psnr(output, target)\n",
        "            test_psnr += psnr.item()\n",
        "\n",
        "    avg_psnr = test_psnr / num_batches\n",
        "    print(f\"Test Avg PSNR: {avg_psnr:.2f} dB\")\n",
        "    return avg_psnr\n",
        "\n",
        "\n",
        "def display_comparison(model, device, dataset, index):\n",
        "    \"\"\"\n",
        "    원본 이미지와 복원된 이미지를 비교하여 출력합니다.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): 복원 모델.\n",
        "        device (str): 'cuda' 또는 'cpu'.\n",
        "        dataset (RandomPatchDataset): 데이터셋 객체.\n",
        "        index (int): 데이터셋에서 이미지를 선택할 인덱스.\n",
        "    \"\"\"\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "    # 데이터셋에서 하나의 샘플 가져오기\n",
        "    input_tensor, target_tensor = dataset[index]\n",
        "\n",
        "    # 모델 입력 준비 (배치 차원 추가, 디바이스 이동)\n",
        "    input_tensor = input_tensor.unsqueeze(0).to(device) # [1, 9, 512, 512]\n",
        "    target_tensor = target_tensor.to(device) # [3, 512, 512]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 모델 추론\n",
        "        restored_tensor = model(input_tensor).squeeze(0) # [3, 512, 512]\n",
        "\n",
        "    # Tensor를 NumPy 이미지로 변환\n",
        "    target_img_np = target_tensor.cpu().permute(1, 2, 0).numpy() # [H, W, C]\n",
        "    restored_img_np = restored_tensor.cpu().permute(1, 2, 0).numpy() # [H, W, C]\n",
        "\n",
        "    # 0-1 범위의 float 이미지를 0-255 범위의 uint8로 변환 (시각화용)\n",
        "    target_img_np = (target_img_np * 255).astype(np.uint8)\n",
        "    restored_img_np = (restored_img_np * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "    # 이미지 출력\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(target_img_np)\n",
        "    plt.title('Original Image (HR)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(restored_img_np)\n",
        "    plt.title(f'Restored Image (DepthwiseSRCNN)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# 훈련된 모델과 테스트 데이터셋을 사용하여 복원된 이미지 비교 출력\n",
        "# 예를 들어, test_dataset의 첫 번째 이미지에 대해 비교\n",
        "display_comparison(model1, device, test_dataset, 4)\n",
        "display_comparison(model1, device, test_dataset, 5)\n",
        "display_comparison(model1, device, test_dataset, 6)\n",
        "display_comparison(model1, device, test_dataset, 7)"
      ],
      "metadata": {
        "id": "J7eetvo70i4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss1)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr1)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mIZkX4wtQcKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('2번 모델 훈련 : BasicSRCNN')\n",
        "train_model2, train_loss2, train_psnr2 = train(model2, device, train_dataloader, optimizer2, criterion, scheduler2, num_epochs)\n"
      ],
      "metadata": {
        "id": "nL7SJh8RQcH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss2)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr2)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LBrJmsB4QcFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('3번 모델 훈련 : ResidualSRCNN')\n",
        "train_model3, train_loss3, train_psnr3 = train(model3, device, train_dataloader, optimizer3, criterion, scheduler3, num_epochs)\n"
      ],
      "metadata": {
        "id": "ag3C39TbQb4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss3)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr3)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jvyW8i08Qb1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('4번 모델 훈련 : DepthwiseSRCNN')\n",
        "train_model4, train_loss4, train_psnr4 = train(model4, device, train_dataloader, optimizer4, criterion, scheduler4, num_epochs)\n"
      ],
      "metadata": {
        "id": "WiLFZyfXQbzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss4)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr4)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iJ-0WFAtQbwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_psnr = 0\n",
        "    num_batches = len(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_tensor, target in test_loader:\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_tensor)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # PSNR 계산\n",
        "            psnr = compute_psnr(output, target)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_psnr += psnr.item()\n",
        "\n",
        "    avg_loss = test_loss / num_batches\n",
        "    avg_psnr = test_psnr / num_batches\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"Average Loss: {avg_loss:.4f}, Average PSNR: {avg_psnr:.2f} dB\")\n",
        "    return avg_loss, avg_psnr\n",
        "\n",
        "print('\\n모델 1 테스트 결과 : MyVersionSRCNN')\n",
        "test_loss1, test_psnr1 = test(train_model1, device, test_dataloader, criterion)\n",
        "print('\\n모델 2 테스트 결과 : BasicSRCNN')\n",
        "test_loss2, test_psnr2 = test(train_model2, device, test_dataloader, criterion)\n",
        "print('\\n모델 3 테스트 결과 : ResidualSRCNN')\n",
        "test_loss3, test_psnr3 = test(train_model3, device, test_dataloader, criterion)\n",
        "print('\\n모델 4 테스트 결과 : DepthwiseSRCNN')\n",
        "test_loss4, test_psnr4 = test(train_model4, device, test_dataloader, criterion)\n",
        "\n",
        "# 모델별 테스트 결과 비교 (선택 사항)\n",
        "print(\"\\n--- 최종 테스트 결과 비교 ---\")\n",
        "print(f\"MyVersionSRCNN: Avg Loss = {test_loss1:.4f}, Avg PSNR = {test_psnr1:.2f} dB\")\n",
        "print(f\"BasicSRCNN:     Avg Loss = {test_loss2:.4f}, Avg PSNR = {test_psnr2:.2f} dB\")\n",
        "print(f\"ResidualSRCNN:  Avg Loss = {test_loss3:.4f}, Avg PSNR = {test_psnr3:.2f} dB\")\n",
        "print(f\"DepthwiseSRCNN: Avg Loss = {test_loss4:.4f}, Avg PSNR = {test_psnr4:.2f} dB\")\n"
      ],
      "metadata": {
        "id": "YyDKqJbIQbtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def display_random_test_image_reconstruction(model, device, test_dataset):\n",
        "    # 랜덤 이미지 선택\n",
        "    random_idx = random.randint(0, len(test_dataset) - 1)\n",
        "    input_tensor, target = test_dataset[random_idx]\n",
        "\n",
        "    # 모델 입력 형태로 변환 및 디바이스 이동\n",
        "    input_tensor_device = input_tensor.unsqueeze(0).to(device) # Add batch dimension\n",
        "\n",
        "    # 모델 예측\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        reconstructed_output = model(input_tensor_device)\n",
        "\n",
        "    # 이미지 시각화를 위해 CPU로 이동 및 numpy 배열로 변환\n",
        "    # (C, H, W) -> (H, W, C)로 차원 변경\n",
        "    input_original = target.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "    reconstructed_image = reconstructed_output.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 원본 이미지 출력\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(input_original)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 복원 이미지 출력\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(reconstructed_image)\n",
        "    plt.title('Reconstructed Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (MyVersionSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model1, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (BasicSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model2, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (ResidualSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model3, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (DepthwiseSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model4, device, test_dataset)"
      ],
      "metadata": {
        "id": "FfpLbCeVQjrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_masked_psnr(model, device, dataloader, dataset, K):\n",
        "    model.eval()\n",
        "    total_masked_psnr = 0\n",
        "    count = 0\n",
        "    dataset.clear_cache() # evaluation 전에 캐시 초기화\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input_tensor, target) in enumerate(dataloader):\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_tensor)\n",
        "\n",
        "            # Batch 내 각 이미지에 대해 masked_psnr 계산\n",
        "            for i in range(output.size(0)):\n",
        "                # 현재 배치에서 해당 이미지의 인덱스에 해당하는 coords 가져오기\n",
        "                # dataloader가 shuffle되어 있을 수 있으므로 original dataset 인덱스 필요\n",
        "                # 하지만 현재 dataloader 구현에서 batch 내 index와 dataset index가 일치하지 않으므로,\n",
        "                # 여기서는 간단하게 dataloader 내 batch index를 활용\n",
        "                # 실제 정확한 구현을 위해서는 dataloader에서 original dataset index도 함께 반환하도록 수정 필요\n",
        "                # 임시 방편으로 현재 batch index + (dataloader batch index * batch_size) 사용\n",
        "                original_dataset_index = idx * dataloader.batch_size + i\n",
        "                if original_dataset_index < len(dataset): # 데이터셋 크기 초과 방지\n",
        "                  coords = dataset.coords[original_dataset_index]\n",
        "                  psnr = masked_psnr(output[i].unsqueeze(0) * 255.0, target[i].unsqueeze(0) * 255.0, coords, K) # PSNR 계산은 보통 0-255 범위에서 수행\n",
        "                  total_masked_psnr += psnr.item()\n",
        "                  count += 1\n",
        "                else:\n",
        "                    print(f\"Warning: Original dataset index {original_dataset_index} out of bounds.\")\n",
        "\n",
        "\n",
        "    avg_masked_psnr = total_masked_psnr / count if count > 0 else 0\n",
        "    return avg_masked_psnr\n",
        "\n",
        "# MyVersionSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr1 = evaluate_masked_psnr(train_model1, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"MyVersionSRCNN Masked PSNR on test set: {avg_masked_psnr1:.2f} dB\")\n",
        "\n",
        "# BasicSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr2 = evaluate_masked_psnr(train_model2, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"BasicSRCNN Masked PSNR on test set: {avg_masked_psnr2:.2f} dB\")\n",
        "\n",
        "# ResidualSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr3 = evaluate_masked_psnr(train_model3, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"ResidualSRCNN Masked PSNR on test set: {avg_masked_psnr3:.2f} dB\")\n",
        "\n",
        "# DepthwiseSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr4 = evaluate_masked_psnr(train_model4, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"DepthwiseSRCNN Masked PSNR on test set: {avg_masked_psnr4:.2f} dB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oTzifYo9Qjg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_reconstruction_and_inputs(model, device, dataset, idx, K):\n",
        "    \"\"\"\n",
        "    주어진 인덱스의 테스트 데이터셋 샘플에 대해 다음을 시각화합니다:\n",
        "    1. 원본 512x512 이미지\n",
        "    2. 모델 입력의 각 컴포넌트 (up128, up256, up512)\n",
        "    3. 분산 기반으로 선택된 512x512 이미지 패치만 (나머지는 검정)\n",
        "    4. 분산 기반으로 선택된 256x256 이미지 패치만 (나머지는 검정)\n",
        "    5. 모델에 의해 복원된 이미지\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 학습된 모델.\n",
        "        device (torch.device): 모델이 로드된 장치 ('cuda' 또는 'cpu').\n",
        "        dataset (Dataset): 테스트 데이터셋 (VariancePatchDataset).\n",
        "        idx (int): 시각화할 샘플의 인덱스.\n",
        "        K (int): 패치 크기.\n",
        "    \"\"\"\n",
        "    dataset.clear_cache() # 캐시 초기화\n",
        "\n",
        "    # 샘플 데이터 가져오기\n",
        "    input_tensor, target = dataset[idx]\n",
        "    image_path = dataset.paths[idx]\n",
        "    coords = dataset.coords[idx]\n",
        "\n",
        "    # 모델 예측\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_tensor_device = input_tensor.unsqueeze(0).to(device)\n",
        "        reconstructed_output = model(input_tensor_device).squeeze(0).cpu()\n",
        "\n",
        "    # 이미지 시각화를 위해 CPU로 이동 및 numpy 배열 변환 (H, W, C)\n",
        "    original_image = target.permute(1, 2, 0).cpu().numpy()\n",
        "    reconstructed_image_np = reconstructed_output.permute(1, 2, 0).numpy()\n",
        "\n",
        "    # 입력 컴포넌트 준비\n",
        "    up128_image_np = input_tensor[:3].permute(1, 2, 0).cpu().numpy()\n",
        "    up256_image_np = input_tensor[3:6].permute(1, 2, 0).cpu().numpy()\n",
        "    up512_image_np = input_tensor[6:].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # 512x512 및 256x256 패치 이미지 준비\n",
        "    pil_512 = Image.open(image_path).convert('RGB')\n",
        "    img_512_np = np.array(pil_512)\n",
        "    masked_512 = np.zeros_like(img_512_np)\n",
        "\n",
        "    for (y, x) in coords:\n",
        "        patch_512 = img_512_np[y:y+K, x:x+K]\n",
        "        masked_512[y:y+K, x:x+K] = patch_512\n",
        "\n",
        "    pil_256 = pil_512.resize((256, 256), Image.BICUBIC)\n",
        "    img_256_np = np.array(pil_256)\n",
        "    masked_256 = np.zeros_like(img_256_np)\n",
        "\n",
        "    coords_256 = [(y//2, x//2) for (y, x) in coords]\n",
        "    for (y2, x2) in coords_256:\n",
        "        patch_256 = img_256_np[y2:y2+K//2, x2:x2+K//2]\n",
        "        masked_256[y2:y2+K//2, x2:x2+K//2] = patch_256\n",
        "\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    axes[0, 0].imshow(original_image)\n",
        "    axes[0, 0].set_title(\"Original 512x512\")\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(up128_image_np)\n",
        "    axes[0, 1].set_title(\"Input: Up128\")\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(up256_image_np)\n",
        "    axes[0, 2].set_title(\"Input: Up256 (Aggregated Patches)\")\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    axes[1, 0].imshow(up512_image_np)\n",
        "    axes[1, 0].set_title(\"Input: Up512 (Aggregated Patches)\")\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(masked_512)\n",
        "    axes[1, 1].set_title(\"Selected 512x512 Patches Only\")\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(masked_256)\n",
        "    axes[1, 2].set_title(\"Selected 256x256 Patches Only\")\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    # 복원된 이미지를 따로 큰 제목으로 표시\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(reconstructed_image_np)\n",
        "    plt.title(\"Reconstructed Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 각 모델에 대해 랜덤 테스트 이미지 하나를 선택하여 시각화\n",
        "random_test_idx = random.randint(0, len(test_dataset) - 1)\n",
        "patch_size = test_dataset.K\n",
        "\n",
        "print(f\"\\n--- 시각화 샘플 인덱스: {random_test_idx} ---\")\n",
        "\n",
        "print(\"\\n--- MyVersionSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model1, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- BasicSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model2, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- ResidualSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model3, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- DepthwiseSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model4, device, test_dataset, random_test_idx, patch_size)\n"
      ],
      "metadata": {
        "id": "f0SFz4FTQjeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "def test(model, device, test_loader, criterion):\n",
        "    \"\"\"\n",
        "    모델을 평가 모드로 전환한 뒤, test_loader의 모든 배치에 대해\n",
        "    손실과 PSNR을 계산합니다.\n",
        "    Returns:\n",
        "      avg_loss: 테스트 데이터셋 전체 평균 MSE 손실\n",
        "      avg_psnr: 테스트 데이터셋 전체 평균 PSNR (dB)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_psnr = 0.0\n",
        "    num_batches = len(test_loader)\n",
        "\n",
        "    # no_grad()로 그래디언트 계산 비활성화\n",
        "    with torch.no_grad():\n",
        "        # tqdm으로 진행률 표시\n",
        "        for input_tensor, target in tqdm(test_loader, desc=\"Test\", leave=False):\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target       = target.to(device)\n",
        "\n",
        "            # mixed‐precision inference\n",
        "            with autocast():\n",
        "                output = model(input_tensor)\n",
        "                loss   = criterion(output, target)\n",
        "\n",
        "            # 손실 및 PSNR accumulate\n",
        "            test_loss += loss.item()\n",
        "            test_psnr += compute_psnr(output, target).item()\n",
        "\n",
        "    # 평균 계산\n",
        "    avg_loss = test_loss / num_batches if num_batches else 0\n",
        "    avg_psnr = test_psnr / num_batches if num_batches else 0\n",
        "\n",
        "    print(f\"[Test]  Loss: {avg_loss:.4f}, Avg PSNR: {avg_psnr:.2f} dB\")\n",
        "    return avg_loss, avg_psnr\n"
      ],
      "metadata": {
        "id": "n0rHXK_hQjbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test 진행\n",
        "test_loss, test_psnr = test(model, device, test_dataloader, criterion)\n"
      ],
      "metadata": {
        "id": "ZqYmM9uTQjZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: testdata 이미지를 랜덤으로 1장 선택해서 원본과 복원된 이미지 psnr 계산\n",
        "\n",
        "import random\n",
        "\n",
        "# 테스트 데이터셋의 인덱스 목록 가져오기\n",
        "test_indices = list(range(len(test_dataset)))\n",
        "\n",
        "# 랜덤으로 하나의 인덱스 선택\n",
        "random_index = random.choice(test_indices)\n",
        "\n",
        "# 선택된 인덱스에 해당하는 샘플 가져오기\n",
        "test_dataset.clear_cache() # 테스트 데이터셋 캐시 초기화 (랜덤 샘플 선택 시 필요)\n",
        "sample_input, sample_target = test_dataset[random_index]\n",
        "\n",
        "# 모델 예측\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # 배치 차원 추가 (모델 입력 형태 맞추기 위해)\n",
        "    sample_input_batch = sample_input.unsqueeze(0).to(device)\n",
        "    restored_output_batch = model(sample_input_batch)\n",
        "    # 배치 차원 제거\n",
        "    restored_output = restored_output_batch.squeeze(0).cpu()\n",
        "\n",
        "# 결과 이미지 출력\n",
        "display_images(sample_target.cpu(), restored_output, title=f\"Random Sample {random_index}: Original vs Restored Image\")\n",
        "\n",
        "# 복원된 이미지와 원본 이미지의 PSNR 계산\n",
        "# sample_target: 원본 이미지 텐서 (3, 512, 512)\n",
        "# restored_output: 모델이 복원한 이미지 텐서 (3, 512, 512)\n",
        "\n",
        "# compute_psnr 함수는 이미 정의되어 있습니다.\n",
        "# compute_psnr 함수는 텐서를 입력받아 GPU 상에서 PSNR을 계산합니다.\n",
        "\n",
        "# PSNR 계산 실행\n",
        "psnr_value = compute_psnr(restored_output, sample_target.cpu()) # CPU 텐서로 변환하여 계산\n",
        "\n",
        "print(f\"\\nPSNR between Original and Restored Image for Random Sample {random_index}: {psnr_value.item():.2f} dB\")"
      ],
      "metadata": {
        "id": "NenleOZuQjWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}