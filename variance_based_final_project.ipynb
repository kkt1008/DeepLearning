{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu3qUY_h7bgR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 압축 해제\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/2025_1 딥러닝/new_COCO2.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(zip_path, 'r')\n",
        "zip_ref.extractall('/dataset')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "VXmFBese7ykQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# psnr, mse 계산 함수\n",
        "# psnr을 계산하기 위해 파이토치 텐서를 넘파이로 변환하는 과정 필요\n",
        "def compute_psnr(img1,img2):\n",
        "    # pytorch 내장 gpu연산을 통해 연산 속도. gpu상에서 텐서 연산을 바로 진행\n",
        "    # gpu->cpu 복사후 numpy로 처리하는 것보다 훨씬 속도가 빠름\n",
        "    mse = torch.mean((img1 - img2)**2) #mse 계산식\n",
        "    psnr = 20 * torch.log10(255.0 / torch.sqrt(mse)) #psnr 계산식 using numpy log10 and sqrt\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "Qqrdee7j7yiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "class VariancePatchDataset(Dataset):\n",
        "    def __init__(self, img_dir, K):\n",
        "        assert 16384 % (K*K) == 0\n",
        "        self.K = K\n",
        "        self.M = 16384 // (K*K) # 메모리 128x128을 고려한 최대 패치수 결정\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.paths = sorted(glob.glob(os.path.join(img_dir, '*.png')))\n",
        "\n",
        "        # Precompute only patch coordinates for lazy feature computation\n",
        "        self.coords = []\n",
        "        for path in self.paths:\n",
        "            pil_l = Image.open(path).convert('L') # 명안 채널만 남겨 grayscale변환\n",
        "            arr = np.array(pil_l) # numpy배열 변환\n",
        "            scores = [] # 분산기반 패치 저장 리스트\n",
        "            # 이미지의 모든 영역을 순회하며 (K x K)크기 패치의 분산 계산\n",
        "            for y in range(0, 512 - K + 1, K):\n",
        "                for x in range(0, 512 - K + 1, K):\n",
        "                    p = arr[y:y+K, x:x+K]\n",
        "                    scores.append((p.var(), y, x)) # 패치 분산, 좌측 상단 좌표(y,x)저장\n",
        "            scores.sort(key=lambda t: t[0], reverse=True) # 분산이 큰 기준으로 내림차순 정렬\n",
        "            self.coords.append([(y, x) for (_, y, x) in scores[:self.M]]) # 정렬된 분산 리스트에서 앞에서 M개의 좌표만 저장\n",
        "\n",
        "        # Lazy feature cache: compute features on first access\n",
        "        self.feature_cache = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # If features already computed, return from cache\n",
        "        if idx in self.feature_cache:\n",
        "            return self.feature_cache[idx]\n",
        "\n",
        "        path = self.paths[idx]\n",
        "        pil = Image.open(path).convert('RGB')\n",
        "        hr = self.to_tensor(pil)\n",
        "\n",
        "        # up128 global\n",
        "        lr128 = pil.resize((128, 128), Image.BICUBIC)\n",
        "        up128 = F.interpolate(\n",
        "            self.to_tensor(lr128).unsqueeze(0),\n",
        "            size=(512, 512), mode='bicubic'\n",
        "        ).squeeze(0)\n",
        "\n",
        "        # aggregate patches\n",
        "        lr256 = pil.resize((256, 256), Image.BICUBIC)\n",
        "        acc256, acc512 = [], []\n",
        "        for (y, x) in self.coords[idx]:\n",
        "            y2, x2 = y//2, x//2\n",
        "            p256 = lr256.crop((x2, y2, x2 + self.K//2, y2 + self.K//2))\n",
        "            acc256.append(\n",
        "                F.interpolate(\n",
        "                    self.to_tensor(p256).unsqueeze(0),\n",
        "                    size=(512, 512), mode='bicubic'\n",
        "                )\n",
        "            )\n",
        "            p512 = pil.crop((x, y, x + self.K, y + self.K))\n",
        "            acc512.append(\n",
        "                F.interpolate(\n",
        "                    self.to_tensor(p512).unsqueeze(0),\n",
        "                    size=(512, 512), mode='bicubic'\n",
        "                )\n",
        "            )\n",
        "\n",
        "        up256 = torch.mean(torch.cat(acc256, dim=0), dim=0)\n",
        "        up512 = torch.mean(torch.cat(acc512, dim=0), dim=0)\n",
        "        inp = torch.cat([up128, up256, up512], dim=0)\n",
        "\n",
        "        # Store in cache for subsequent epochs\n",
        "        self.feature_cache[idx] = (inp, hr)\n",
        "        return inp, hr\n",
        "\n",
        "    def clear_cache(self):\n",
        "        \"\"\"Epoch 단위로 캐시된 feature를 비웁니다.\"\"\"\n",
        "        self.feature_cache.clear()\n"
      ],
      "metadata": {
        "id": "G2q3Z6Ad7yfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device : \", device)\n"
      ],
      "metadata": {
        "id": "6akwKIA8sOB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 복원 네트워크\n",
        "class MyVersionSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=3):\n",
        "        super(MyVersionSRCNN, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # 1) Depthwise Conv 5×5 방법-파라미터, 연산량을 모두 감소\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=in_channels),\n",
        "            # 2) Pointwise Conv 1×1 → 64채널\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 32, kernel_size=1),         # dimensionality reduction\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)  # reconstruction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x[:, :3] 은 global up128 의 첫 3채널\n",
        "        res = self.layers(x) # 잔차 학습(Residual Learning)---학습속도 계선\n",
        "        return  (res + x[:, :3, :, :]).clamp(0,1)# output range [0,1]\n",
        "\n",
        "# 선택가능 패치 개수 : M = 16384 // (K*K) = 64, so in_ch = 3 + 6*64 = 387\n",
        "model1 = MyVersionSRCNN(in_channels=9).to(device)"
      ],
      "metadata": {
        "id": "wyukmYZcIvR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Basic SRCNN (adapted for 9-channel input)\n",
        "class BasicSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(BasicSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, padding=4),  # feature extraction\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),                       # non-linear mapping\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)   # reconstruction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).clamp(0, 1)\n",
        "\n",
        "model2 = BasicSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "xHCLfSGssvlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Residual SRCNN\n",
        "class ResidualSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(ResidualSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, padding=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.net(x)\n",
        "        # add global up128 (first 3 channels) as residual connection\n",
        "        return (res + x[:, :3, :, :]).clamp(0, 1)\n",
        "\n",
        "model3 = ResidualSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "pU0Wh7Z4svi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Depthwise-Separable SRCNN\n",
        "class DepthwiseSRCNN(nn.Module):\n",
        "    def __init__(self, in_channels=9, out_channels=3):\n",
        "        super(DepthwiseSRCNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # depthwise 9x9\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=9, padding=4, groups=in_channels),\n",
        "            # pointwise 1x1\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, out_channels, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).clamp(0, 1)\n",
        "\n",
        "model4 = DepthwiseSRCNN(in_channels=9).to(device)\n"
      ],
      "metadata": {
        "id": "f405xjdYsvg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model1, (9, 512, 512)) # MyVersionSRCNN\n",
        "summary(model2, (9, 512, 512)) # BasicSRCNN\n",
        "summary(model3, (9, 512, 512)) # ResidualSRCNN\n",
        "summary(model4, (9, 512, 512)) # DepthwiseSRCNN"
      ],
      "metadata": {
        "id": "Hjk9ngLh7yas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CPU 코어 수:\", os.cpu_count())"
      ],
      "metadata": {
        "id": "A2Pn34snV6mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dataset\n",
        "train_dataset = VariancePatchDataset(img_dir='/dataset/new_COCO2/Train',K=8)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=3, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "test_dataset = VariancePatchDataset(img_dir='/dataset/new_COCO2/Test', K=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=3, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "DbeQoN_d7yX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset shape 확인\n",
        "print(f\"Train dataset : {len(train_dataset)}\")\n",
        "print(f\"Test dataset : {len(test_dataset)}\")\n",
        "\n",
        "sample_input, sample_output = train_dataset[0]\n",
        "print(f\"Train dataset input shape(3개의 scale의 rgb이미지): {sample_input.shape}\")\n",
        "print(f\"Train dataset output shape(복원된 이미지): {sample_output.shape}\")\n",
        "\n",
        "sample_input, sample_output = test_dataset[0]\n",
        "print(f\"Test dataset input shape: {sample_input.shape}\")\n",
        "print(f\"Test dataset output shape: {sample_output.shape}\")"
      ],
      "metadata": {
        "id": "3M-6JkN-7yVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 설정\n",
        "learning_rate = 1e-3 # 학습률\n",
        "criterion = nn.MSELoss() # loss fuction\n",
        "num_epochs = 30 # number of epochs\n",
        "\n",
        "# 1번모델========================================================\n",
        "# optimizer\n",
        "optimizer1 = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler1 = optim.lr_scheduler.StepLR(optimizer1, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 2번모델==========================================================\n",
        "# optimizer\n",
        "optimizer2 = optim.Adam(model2.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler2 = optim.lr_scheduler.StepLR(optimizer2, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 3번모델==========================================================\n",
        "# optimizer\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler3 = optim.lr_scheduler.StepLR(optimizer3, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n",
        "\n",
        "# 4번모델==========================================================\n",
        "# optimizer\n",
        "optimizer4 = optim.Adam(model4.parameters(), lr=learning_rate)\n",
        "\n",
        "# shceduler(learning rate 조절)\n",
        "scheduler4 = optim.lr_scheduler.StepLR(optimizer4, step_size=10, gamma=0.1) # 10 epoch마다 0.1배\n"
      ],
      "metadata": {
        "id": "FQppp_pU7ySu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, sceduler, num_epochs, time_limit_hours=10):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    train_psnr = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_dataset.clear_cache() # epoch마다 캐시 초기화\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        epoch_psnr = 0\n",
        "        num_batches = len(train_loader)\n",
        "        scaler = GradScaler()\n",
        "        for input_tensor, target in train_loader:\n",
        "            input_tensor = input_tensor.to(device)  # [B, 9, 512, 512]\n",
        "            target = target.to(device)              # [B, 3, 512, 512]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                output = model(input_tensor)\n",
        "                loss = criterion(output, target)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # PSNR 계산\n",
        "            psnr = compute_psnr(output, target)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_psnr += psnr.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        avg_loss = epoch_loss / num_batches\n",
        "        avg_psnr = epoch_psnr / num_batches\n",
        "        train_loss.append(avg_loss)\n",
        "        train_psnr.append(avg_psnr)\n",
        "\n",
        "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}, Avg PSNR: {avg_psnr:.2f} dB\")\n",
        "\n",
        "        # 시간 제한 확인\n",
        "        elapsed_time = time.time() - start_time\n",
        "        if elapsed_time > time_limit_hours * 3600:\n",
        "            print(\"Training stopped: 10-hour limit reached.\")\n",
        "            break\n",
        "\n",
        "    return model, train_loss, train_psnr\n"
      ],
      "metadata": {
        "id": "ar6doMeb7yP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('1번 모델 훈련 : MyVersionSRCNN')\n",
        "train_model1, train_loss1, train_psnr1 = train(model1, device, train_dataloader, optimizer1, criterion, scheduler1, num_epochs)\n"
      ],
      "metadata": {
        "id": "XgIMQ1oMVPTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss1)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr1)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "87WbHYrET5B6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('2번 모델 훈련 : BasicSRCNN')\n",
        "train_model2, train_loss2, train_psnr2 = train(model2, device, train_dataloader, optimizer2, criterion, scheduler2, num_epochs)\n"
      ],
      "metadata": {
        "id": "aXwLkgbWvvRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss2)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr2)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BKxNsjFewAAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('3번 모델 훈련 : ResidualSRCNN')\n",
        "train_model3, train_loss3, train_psnr3 = train(model3, device, train_dataloader, optimizer3, criterion, scheduler3, num_epochs)\n"
      ],
      "metadata": {
        "id": "3UFeitisvwGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss3)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr3)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jV5vTmzjwCyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('4번 모델 훈련 : DepthwiseSRCNN')\n",
        "train_model4, train_loss4, train_psnr4 = train(model4, device, train_dataloader, optimizer4, criterion, scheduler4, num_epochs)\n"
      ],
      "metadata": {
        "id": "peYe-SwDvwD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프로 결과 시각화\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_loss4)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_psnr4)\n",
        "plt.title('Training PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K1VQ0-82wE97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_psnr = 0\n",
        "    num_batches = len(test_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_tensor, target in test_loader:\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_tensor)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # PSNR 계산\n",
        "            psnr = compute_psnr(output, target)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            test_psnr += psnr.item()\n",
        "\n",
        "    avg_loss = test_loss / num_batches\n",
        "    avg_psnr = test_psnr / num_batches\n",
        "\n",
        "    print(f\"\\nTest Results:\")\n",
        "    print(f\"Average Loss: {avg_loss:.4f}, Average PSNR: {avg_psnr:.2f} dB\")\n",
        "    return avg_loss, avg_psnr\n",
        "\n",
        "print('\\n모델 1 테스트 결과 : MyVersionSRCNN')\n",
        "test_loss1, test_psnr1 = test(train_model1, device, test_dataloader, criterion)\n",
        "print('\\n모델 2 테스트 결과 : BasicSRCNN')\n",
        "test_loss2, test_psnr2 = test(train_model2, device, test_dataloader, criterion)\n",
        "print('\\n모델 3 테스트 결과 : ResidualSRCNN')\n",
        "test_loss3, test_psnr3 = test(train_model3, device, test_dataloader, criterion)\n",
        "print('\\n모델 4 테스트 결과 : DepthwiseSRCNN')\n",
        "test_loss4, test_psnr4 = test(train_model4, device, test_dataloader, criterion)\n",
        "\n",
        "# 모델별 테스트 결과 비교 (선택 사항)\n",
        "print(\"\\n--- 최종 테스트 결과 비교 ---\")\n",
        "print(f\"MyVersionSRCNN: Avg Loss = {test_loss1:.4f}, Avg PSNR = {test_psnr1:.2f} dB\")\n",
        "print(f\"BasicSRCNN:     Avg Loss = {test_loss2:.4f}, Avg PSNR = {test_psnr2:.2f} dB\")\n",
        "print(f\"ResidualSRCNN:  Avg Loss = {test_loss3:.4f}, Avg PSNR = {test_psnr3:.2f} dB\")\n",
        "print(f\"DepthwiseSRCNN: Avg Loss = {test_loss4:.4f}, Avg PSNR = {test_psnr4:.2f} dB\")\n"
      ],
      "metadata": {
        "id": "8MygZp_GQEqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def display_random_test_image_reconstruction(model, device, test_dataset):\n",
        "    # 랜덤 이미지 선택\n",
        "    random_idx = random.randint(0, len(test_dataset) - 1)\n",
        "    input_tensor, target = test_dataset[random_idx]\n",
        "\n",
        "    # 모델 입력 형태로 변환 및 디바이스 이동\n",
        "    input_tensor_device = input_tensor.unsqueeze(0).to(device) # Add batch dimension\n",
        "\n",
        "    # 모델 예측\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        reconstructed_output = model(input_tensor_device)\n",
        "\n",
        "    # 이미지 시각화를 위해 CPU로 이동 및 numpy 배열로 변환\n",
        "    # (C, H, W) -> (H, W, C)로 차원 변경\n",
        "    input_original = target.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "    reconstructed_image = reconstructed_output.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 원본 이미지 출력\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(input_original)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 복원 이미지 출력\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(reconstructed_image)\n",
        "    plt.title('Reconstructed Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (MyVersionSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model1, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (BasicSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model2, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (ResidualSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model3, device, test_dataset)\n",
        "\n",
        "print(\"\\n--- 랜덤 테스트 이미지 복원 결과 (DepthwiseSRCNN) ---\")\n",
        "display_random_test_image_reconstruction(train_model4, device, test_dataset)"
      ],
      "metadata": {
        "id": "2cT7e8EeQZSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) masked_psnr 함수\n",
        "def masked_psnr(output, target, coords, K):\n",
        "    \"\"\"\n",
        "    output, target: [B,3,512,512]\n",
        "    coords: list of (y,x) for this sample\n",
        "    \"\"\"\n",
        "    mse_map = (output - target).pow(2)      # [B,3,512,512]\n",
        "    mask    = torch.ones_like(mse_map)      # same shape\n",
        "    for (y, x) in coords:\n",
        "        mask[:, :, y:y+K, x:x+K] = 0\n",
        "    masked_mse = (mse_map * mask).sum() / mask.sum()\n",
        "    return 10 * torch.log10(255.0**2 / (masked_mse ))"
      ],
      "metadata": {
        "id": "pVwU0phfdg77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_masked_psnr(model, device, dataloader, dataset, K):\n",
        "    model.eval()\n",
        "    total_masked_psnr = 0\n",
        "    count = 0\n",
        "    dataset.clear_cache() # evaluation 전에 캐시 초기화\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (input_tensor, target) in enumerate(dataloader):\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            output = model(input_tensor)\n",
        "\n",
        "            # Batch 내 각 이미지에 대해 masked_psnr 계산\n",
        "            for i in range(output.size(0)):\n",
        "                # 현재 배치에서 해당 이미지의 인덱스에 해당하는 coords 가져오기\n",
        "                # dataloader가 shuffle되어 있을 수 있으므로 original dataset 인덱스 필요\n",
        "                # 하지만 현재 dataloader 구현에서 batch 내 index와 dataset index가 일치하지 않으므로,\n",
        "                # 여기서는 간단하게 dataloader 내 batch index를 활용\n",
        "                # 실제 정확한 구현을 위해서는 dataloader에서 original dataset index도 함께 반환하도록 수정 필요\n",
        "                # 임시 방편으로 현재 batch index + (dataloader batch index * batch_size) 사용\n",
        "                original_dataset_index = idx * dataloader.batch_size + i\n",
        "                if original_dataset_index < len(dataset): # 데이터셋 크기 초과 방지\n",
        "                  coords = dataset.coords[original_dataset_index]\n",
        "                  psnr = masked_psnr(output[i].unsqueeze(0) * 255.0, target[i].unsqueeze(0) * 255.0, coords, K) # PSNR 계산은 보통 0-255 범위에서 수행\n",
        "                  total_masked_psnr += psnr.item()\n",
        "                  count += 1\n",
        "                else:\n",
        "                    print(f\"Warning: Original dataset index {original_dataset_index} out of bounds.\")\n",
        "\n",
        "\n",
        "    avg_masked_psnr = total_masked_psnr / count if count > 0 else 0\n",
        "    return avg_masked_psnr\n",
        "\n",
        "# MyVersionSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr1 = evaluate_masked_psnr(train_model1, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"MyVersionSRCNN Masked PSNR on test set: {avg_masked_psnr1:.2f} dB\")\n",
        "\n",
        "# BasicSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr2 = evaluate_masked_psnr(train_model2, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"BasicSRCNN Masked PSNR on test set: {avg_masked_psnr2:.2f} dB\")\n",
        "\n",
        "# ResidualSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr3 = evaluate_masked_psnr(train_model3, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"ResidualSRCNN Masked PSNR on test set: {avg_masked_psnr3:.2f} dB\")\n",
        "\n",
        "# DepthwiseSRCNN 모델에 대한 masked PSNR 계산\n",
        "avg_masked_psnr4 = evaluate_masked_psnr(train_model4, device, test_dataloader, test_dataset, K=16)\n",
        "print(f\"DepthwiseSRCNN Masked PSNR on test set: {avg_masked_psnr4:.2f} dB\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hhCU8KUQO8kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def plot_reconstruction_and_inputs(model, device, dataset, idx, K):\n",
        "    \"\"\"\n",
        "    주어진 인덱스의 테스트 데이터셋 샘플에 대해 다음을 시각화합니다:\n",
        "    1. 원본 512x512 이미지\n",
        "    2. 모델 입력의 각 컴포넌트 (up128, up256, up512)\n",
        "    3. 분산 기반으로 선택된 512x512 이미지 패치만 (나머지는 검정)\n",
        "    4. 분산 기반으로 선택된 256x256 이미지 패치만 (나머지는 검정)\n",
        "    5. 모델에 의해 복원된 이미지\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): 학습된 모델.\n",
        "        device (torch.device): 모델이 로드된 장치 ('cuda' 또는 'cpu').\n",
        "        dataset (Dataset): 테스트 데이터셋 (VariancePatchDataset).\n",
        "        idx (int): 시각화할 샘플의 인덱스.\n",
        "        K (int): 패치 크기.\n",
        "    \"\"\"\n",
        "    dataset.clear_cache() # 캐시 초기화\n",
        "\n",
        "    # 샘플 데이터 가져오기\n",
        "    input_tensor, target = dataset[idx]\n",
        "    image_path = dataset.paths[idx]\n",
        "    coords = dataset.coords[idx]\n",
        "\n",
        "    # 모델 예측\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_tensor_device = input_tensor.unsqueeze(0).to(device)\n",
        "        reconstructed_output = model(input_tensor_device).squeeze(0).cpu()\n",
        "\n",
        "    # 이미지 시각화를 위해 CPU로 이동 및 numpy 배열 변환 (H, W, C)\n",
        "    original_image = target.permute(1, 2, 0).cpu().numpy()\n",
        "    reconstructed_image_np = reconstructed_output.permute(1, 2, 0).numpy()\n",
        "\n",
        "    # 입력 컴포넌트 준비\n",
        "    up128_image_np = input_tensor[:3].permute(1, 2, 0).cpu().numpy()\n",
        "    up256_image_np = input_tensor[3:6].permute(1, 2, 0).cpu().numpy()\n",
        "    up512_image_np = input_tensor[6:].permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # 512x512 및 256x256 패치 이미지 준비\n",
        "    pil_512 = Image.open(image_path).convert('RGB')\n",
        "    img_512_np = np.array(pil_512)\n",
        "    masked_512 = np.zeros_like(img_512_np)\n",
        "\n",
        "    for (y, x) in coords:\n",
        "        patch_512 = img_512_np[y:y+K, x:x+K]\n",
        "        masked_512[y:y+K, x:x+K] = patch_512\n",
        "\n",
        "    pil_256 = pil_512.resize((256, 256), Image.BICUBIC)\n",
        "    img_256_np = np.array(pil_256)\n",
        "    masked_256 = np.zeros_like(img_256_np)\n",
        "\n",
        "    coords_256 = [(y//2, x//2) for (y, x) in coords]\n",
        "    for (y2, x2) in coords_256:\n",
        "        patch_256 = img_256_np[y2:y2+K//2, x2:x2+K//2]\n",
        "        masked_256[y2:y2+K//2, x2:x2+K//2] = patch_256\n",
        "\n",
        "\n",
        "    # 시각화\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "    axes[0, 0].imshow(original_image)\n",
        "    axes[0, 0].set_title(\"Original 512x512\")\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    axes[0, 1].imshow(up128_image_np)\n",
        "    axes[0, 1].set_title(\"Input: Up128\")\n",
        "    axes[0, 1].axis('off')\n",
        "\n",
        "    axes[0, 2].imshow(up256_image_np)\n",
        "    axes[0, 2].set_title(\"Input: Up256 (Aggregated Patches)\")\n",
        "    axes[0, 2].axis('off')\n",
        "\n",
        "    axes[1, 0].imshow(up512_image_np)\n",
        "    axes[1, 0].set_title(\"Input: Up512 (Aggregated Patches)\")\n",
        "    axes[1, 0].axis('off')\n",
        "\n",
        "    axes[1, 1].imshow(masked_512)\n",
        "    axes[1, 1].set_title(\"Selected 512x512 Patches Only\")\n",
        "    axes[1, 1].axis('off')\n",
        "\n",
        "    axes[1, 2].imshow(masked_256)\n",
        "    axes[1, 2].set_title(\"Selected 256x256 Patches Only\")\n",
        "    axes[1, 2].axis('off')\n",
        "\n",
        "    # 복원된 이미지를 따로 큰 제목으로 표시\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(reconstructed_image_np)\n",
        "    plt.title(\"Reconstructed Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 각 모델에 대해 랜덤 테스트 이미지 하나를 선택하여 시각화\n",
        "random_test_idx = random.randint(0, len(test_dataset) - 1)\n",
        "patch_size = test_dataset.K\n",
        "\n",
        "print(f\"\\n--- 시각화 샘플 인덱스: {random_test_idx} ---\")\n",
        "\n",
        "print(\"\\n--- MyVersionSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model1, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- BasicSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model2, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- ResidualSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model3, device, test_dataset, random_test_idx, patch_size)\n",
        "\n",
        "print(\"\\n--- DepthwiseSRCNN 결과 ---\")\n",
        "plot_reconstruction_and_inputs(train_model4, device, test_dataset, random_test_idx, patch_size)\n"
      ],
      "metadata": {
        "id": "O-U_1ImuR58f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}